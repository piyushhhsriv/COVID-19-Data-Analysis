{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COVID-19 Data Analysis â€” COVID vs Happiness\n",
        "\n",
        "This notebook loads the provided COVID-19 datasets (confirmed & deaths) and the Worldwide Happiness Report, performs cleaning and exploratory data analysis (EDA), merges the datasets, and explores relationships between COVID-19 impact and happiness indicators (Score, GDP per capita, Healthy life expectancy, Social support, etc.).\n",
        "\n",
        "Notes:\n",
        "- Place the CSV files in the same folder as this notebook (covid19_Confirmed_dataset.csv, covid19_deaths_dataset.csv, worldwide_happiness_report.csv).\n",
        "- The notebook uses simple heuristics (grouping, fuzzy-matching) to merge country names; manual adjustments may be needed for certain names.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Standard imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from difflib import get_close_matches\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load datasets\n",
        "cov_deaths = pd.read_csv('covid19_deaths_dataset.csv')\n",
        "cov_confirmed = pd.read_csv('covid19_Confirmed_dataset.csv')\n",
        "happiness = pd.read_csv('worldwide_happiness_report.csv')\n",
        "\n",
        "print('deaths shape:', cov_deaths.shape)\n",
        "print('confirmed shape:', cov_confirmed.shape)\n",
        "print('happiness shape:', happiness.shape)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect the COVID data format\n",
        "The COVID files are in the 'wide' format with date columns. We'll transform to aggregated country-level latest totals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# helper: get the last date column available in a wide-format covid dataframe\n",
        "def last_date_col(df):\n",
        "    # date-like columns generally start after the 4th column (Province/State,Country/Region,Lat,Long)\n",
        "    cols = df.columns.tolist()\n",
        "    # find first date column by trying to parse; fallback to last column\n",
        "    for i, c in enumerate(cols):\n",
        "        try:\n",
        "            # month/day/year format may raise or succeed\n",
        "            datetime.strptime(c, '%m/%d/%y')\n",
        "            first_date_idx = i\n",
        "            break\n",
        "        except Exception:\n",
        "            continue\n",
        "    return cols[first_date_idx:]\n",
        "\n",
        "date_cols_deaths = last_date_col(cov_deaths)\n",
        "date_cols_conf = last_date_col(cov_confirmed)\n",
        "print('deaths date columns sample:', date_cols_deaths[:3], '... last:', date_cols_deaths[-1])\n",
        "print('confirmed date columns sample:', date_cols_conf[:3], '... last:', date_cols_conf[-1])\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Aggregate to country-level using the latest available date\n",
        "latest_death_col = date_cols_deaths[-1]\n",
        "latest_conf_col = date_cols_conf[-1]\n",
        "\n",
        "deaths_by_country = cov_deaths.groupby('Country/Region')[date_cols_deaths].sum().reset_index()\n",
        "confirmed_by_country = cov_confirmed.groupby('Country/Region')[date_cols_conf].sum().reset_index()\n",
        "\n",
        "deaths_latest = deaths_by_country[['Country/Region', latest_death_col]].rename(columns={latest_death_col: 'Deaths_latest'})\n",
        "conf_latest = confirmed_by_country[['Country/Region', latest_conf_col]].rename(columns={latest_conf_col: 'Confirmed_latest'})\n",
        "\n",
        "cov_latest = pd.merge(conf_latest, deaths_latest, on='Country/Region', how='outer')\n",
        "cov_latest['Confirmed_latest'] = cov_latest['Confirmed_latest'].fillna(0).astype(int)\n",
        "cov_latest['Deaths_latest'] = cov_latest['Deaths_latest'].fillna(0).astype(int)\n",
        "cov_latest['CFR'] = np.where(cov_latest['Confirmed_latest']>0, cov_latest['Deaths_latest'] / cov_latest['Confirmed_latest'], np.nan)\n",
        "cov_latest.sort_values('Confirmed_latest', ascending=False).head()\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare happiness dataframe\n",
        "- Clean column names and types\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "h = happiness.copy()\n",
        "# Standardize column names\n",
        "h.columns = [c.strip() for c in h.columns]\n",
        "h = h.rename(columns={'Country or region': 'Country', 'Overall rank': 'Rank'})\n",
        "h.head()\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge datasets (fuzzy country matching)\n",
        "We'll try direct matches first, then use difflib.get_close_matches for unmatched countries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cov = cov_latest.copy()\n",
        "cov = cov.rename(columns={'Country/Region': 'Country'})\n",
        "\n",
        "# Build mapping from COVID country names to Happiness country names using best matches\n",
        "h_countries = h['Country'].unique().tolist()\n",
        "cov_countries = cov['Country'].unique().tolist()\n",
        "\n",
        "mapping = {}\n",
        "for c in cov_countries:\n",
        "    if c in h_countries:\n",
        "        mapping[c] = c\n",
        "    else:\n",
        "        # try close match\n",
        "        matches = get_close_matches(c, h_countries, n=1, cutoff=0.8)\n",
        "        if matches:\n",
        "            mapping[c] = matches[0]\n",
        "        else:\n",
        "            # small manual fixes for common name differences\n",
        "            manual = {\n",
        "                'US': 'United States',\n",
        "                'Russia': 'Russia',\n",
        "                'Korea, South': 'South Korea',\n",
        "                'Iran': 'Iran',\n",
        "                'Taiwan*': 'Taiwan',\n",
        "                'Vietnam': 'Vietnam',\n",
        "                'Congo (Kinshasa)': 'Congo (Kinshasa)',\n",
        "                'Bolivia': 'Bolivia',\n",
        "                'Czechia': 'Czech Republic',\n",
        "                'Venezuela': 'Venezuela',\n",
        "                'United Kingdom': 'United Kingdom'\n",
        "            }\n",
        "            if c in manual:\n",
        "                mapping[c] = manual[c]\n",
        "            else:\n",
        "                mapping[c] = None\n",
        "\n",
        "# Apply mapping and build merged df\n",
        "cov['Country_happiness'] = cov['Country'].map(mapping)\n",
        "merged = cov.merge(h, left_on='Country_happiness', right_on='Country', how='left', suffixes=('_cov','_happy'))\n",
        "\n",
        "print('Total COVID countries:', len(cov_countries))\n",
        "print('Mapped to happiness names (not null):', merged['Country_happiness'].notnull().sum())\n",
        "merged[['Country', 'Country_happiness', 'Deaths_latest', 'Confirmed_latest', 'Score', 'GDP per capita']].head()\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show unmatched countries for manual inspection\n",
        "unmatched = merged[merged['Score'].isnull()][['Country', 'Country_happiness']]\n",
        "unmatched.head(30)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If there are unmatched countries you care about, you can update the `manual` mapping above and re-run the merge.\n",
        "\n",
        "Next: create analysis metrics and visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prepare final analysis dataframe (drop rows without happiness Score)\n",
        "analysis = merged.dropna(subset=['Score']).copy()\n",
        "\n",
        "# Create per-100-cases and per-100-deaths metrics where meaningful\n",
        "analysis['Deaths_per_Confirmed_pct'] = analysis['CFR'] * 100\n",
        "analysis['log_confirmed'] = np.log1p(analysis['Confirmed_latest'])\n",
        "analysis['log_deaths'] = np.log1p(analysis['Deaths_latest'])\n",
        "\n",
        "analysis[['Country_cov','Country_happiness','Score','GDP per capita','Deaths_latest','Confirmed_latest','Deaths_per_Confirmed_pct']].sample(10)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations\n",
        "1) Scatter: Happiness Score vs CFR (Deaths / Confirmed)\n",
        "2) Scatter: Happiness Score vs Confirmed (log)\n",
        "3) Correlation heatmap between happiness indicators and COVID metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=analysis, x='Score', y='Deaths_per_Confirmed_pct')\n",
        "plt.xlabel('Happiness Score')\n",
        "plt.ylabel('Deaths / Confirmed (%)')\n",
        "plt.title('Happiness Score vs COVID Case Fatality (%)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=analysis, x='Score', y='log_confirmed')\n",
        "plt.xlabel('Happiness Score')\n",
        "plt.ylabel('log(Confirmed + 1)')\n",
        "plt.title('Happiness Score vs Log Confirmed Cases')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Correlation matrix\n",
        "corr_cols = ['Score','GDP per capita','Social support','Healthy life expectancy','Freedom to make life choices','Generosity','Perceptions of corruption','Confirmed_latest','Deaths_latest','CFR']\n",
        "sub = analysis[corr_cols].copy()\n",
        "sub = sub.dropna()\n",
        "corr = sub.corr()\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "plt.title('Correlation between Happiness indicators and COVID metrics')\n",
        "plt.show()\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple statistical checks\n",
        "- Compute Pearson correlation between Score and CFR, Score and log_confirmed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "df_corr = sub.dropna()\n",
        "for a,b in [('Score','CFR'), ('Score','log_confirmed')]:\n",
        "    x = df_corr[a].values\n",
        "    y = df_corr[b].values if b in df_corr else analysis[b].values\n",
        "    try:\n",
        "        r, p = pearsonr(x, y)\n",
        "        print(f'Pearson r between {a} and {b}: r={r:.3f}, p={p:.3g}')\n",
        "    except Exception as e:\n",
        "        print('Could not compute for', a, b, '->', e)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial conclusions & next steps\n",
        "- The scatter plots and correlation matrix give a first look at whether happier countries experienced lower CFR or fewer cases per country (note: per-country totals are strongly influenced by population size and testing policies).\n",
        "- Next steps to improve rigor:\n",
        "  - Obtain population data to compute per-capita metrics (cases/deaths per 100k).\n",
        "  - Use time-series analysis to compare pandemic trajectories and relate them to policy / social indicators.\n",
        "  - Improve country-name matching (use ISO codes or a curated mapping).\n",
        "  - Consider controlling for confounders (age structure, testing rates, urbanization).\n",
        "\n",
        "Save this notebook and include the generated plots in your report/README.\n"
      ]
    }
  ]
}
